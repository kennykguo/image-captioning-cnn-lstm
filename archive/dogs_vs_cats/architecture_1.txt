Layer (type)                  Output Shape              Param #   
=================================================================
input_1 (InputLayer)          (None, 128, 128, 3)       0         
_________________________________________________________________
conv2d_1 (Conv2D)             (None, 128, 128, 32)      896       
_________________________________________________________________
batch_normalization_1 (BatchNormalization) (None, 128, 128, 32)    128       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2D) (None, 64, 64, 32)       0         
_________________________________________________________________
dropout_1 (Dropout)           (None, 64, 64, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)             (None, 64, 64, 64)       18496     
_________________________________________________________________
batch_normalization_2 (BatchNormalization) (None, 64, 64, 64)      256       
_________________________________________________________________
max_pooling2d_2 (MaxPooling2D) (None, 32, 32, 64)       0         
_________________________________________________________________
dropout_2 (Dropout)           (None, 32, 32, 64)        0         
_________________________________________________________________
conv2d_3 (Conv2D)             (None, 32, 32, 128)      73856     
_________________________________________________________________
batch_normalization_3 (BatchNormalization) (None, 32, 32, 128)     512       
_________________________________________________________________
max_pooling2d_3 (MaxPooling2D) (None, 16, 16, 128)      0         
_________________________________________________________________
dropout_3 (Dropout)           (None, 16, 16, 128)       0         
_________________________________________________________________
flatten_1 (Flatten)           (None, 32768)             0         
_________________________________________________________________
dense_1 (Dense)               (None, 256)               8388864   
_________________________________________________________________
batch_normalization_4 (BatchNormalization) (None, 256)           1024       
_________________________________________________________________
dropout_4 (Dropout)           (None, 256)               0         
_________________________________________________________________
dense_2 (Dense)               (None, 10)                2570      
=================================================================
Total params: 8,488,602
Trainable params: 8,487,626
Non-trainable params: 976

### ------------------------------------------------------------------------------------
Architecture for Input Size (128, 128, 3)
Input Layer

Input shape: (128, 128, 3)
First Convolutional Layer

Convolution: 32 filters, kernel size (3, 3), stride (1, 1), padding 'same'
Activation: ReLU
Batch Normalization
Pooling: Max pooling with pool size (2, 2), stride (2, 2)
Dropout: 0.25
Output shape: (64, 64, 32)
Second Convolutional Layer

Convolution: 64 filters, kernel size (3, 3), stride (1, 1), padding 'same'
Activation: ReLU
Batch Normalization
Pooling: Max pooling with pool size (2, 2), stride (2, 2)
Dropout: 0.25
Output shape: (32, 32, 64)
Third Convolutional Layer

Convolution: 128 filters, kernel size (3, 3), stride (1, 1), padding 'same'
Activation: ReLU
Batch Normalization
Pooling: Max pooling with pool size (2, 2), stride (2, 2)
Dropout: 0.25
Output shape: (16, 16, 128)
Flatten Layer

Flattens the output from the previous layer
Output shape: (16 * 16 * 128) = (32768)
Fully Connected (Dense) Layer

Dense layer with 256 units
Activation: ReLU
Batch Normalization
Dropout: 0.5
Output shape: (256)
Output Layer

Dense layer with 10 units (for example, for 10 classes)
Activation: Softmax
Output shape: (10)